<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Tech Blog on ★❤✰ Vicki Boykis ★❤✰</title><link>https://veekaybee.github.io/</link><description>Recent content in Tech Blog on ★❤✰ Vicki Boykis ★❤✰</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><copyright>Copyright © 2021, Vicki Boykis.</copyright><lastBuildDate>Mon, 05 Dec 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://veekaybee.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>The cloudy layers of modern-day programming</title><link>https://veekaybee.github.io/2022/12/05/the-cloudy-layers-of-modern-day-programming/</link><pubDate>Mon, 05 Dec 2022 00:00:00 +0000</pubDate><guid>https://veekaybee.github.io/2022/12/05/the-cloudy-layers-of-modern-day-programming/</guid><description>Composition X, Kandinsky
Recently, I’ve come to the realization that much of what we do in modern software development is not true software engineering. We spend the majority of our days trying to configure OpenSprocket 2.3.1 to work with NeoGidgetPro5, both of which were developed by two different third-party vendors and available as only as proprietary services in FoogleServiceCloud.
The name of this activity is, brilliantly summarized as VendorOps, from this blog post,</description></item><item><title>Some notes on the Stable Diffusion safety filter</title><link>https://veekaybee.github.io/2022/11/18/some-notes-on-the-stable-diffusion-safety-filter/</link><pubDate>Fri, 18 Nov 2022 00:00:00 +0000</pubDate><guid>https://veekaybee.github.io/2022/11/18/some-notes-on-the-stable-diffusion-safety-filter/</guid><description>In time for NeurIPS 2022, there are a lot of interesting papers and preprints being published on ArXiv.
One I ran into recently was &amp;ldquo;Red-Teaming the Stable Diffusion Safety Filter.&amp;rdquo;
Having worked on content moderation before, the concept of how to moderate the content of a deep learning model was interesting to me and I thought it benefitted from a broader look.
Let&amp;rsquo;s dive in by starting with the paper title.</description></item><item><title>How I learn machine learning</title><link>https://veekaybee.github.io/2022/11/10/how-i-learn-machine-learning/</link><pubDate>Thu, 10 Nov 2022 00:00:00 +0000</pubDate><guid>https://veekaybee.github.io/2022/11/10/how-i-learn-machine-learning/</guid><description>&amp;ldquo;Almost all advice is contextual, yet it is rarely delivered with any context&amp;rdquo;, writes Justin in this post of things he&amp;rsquo;s learned in 20 years as a developer.
The context for the advice I&amp;rsquo;m about to share is: I started without an engineering background and through hard work and a lot of luck became a machine learning engineer.
My overarching goal as an MLE is to continuously work towards designing and deploying well-designed, and transparent machine learning systems and to learn the best software engineering practices to do so.</description></item><item><title>On the team as a system</title><link>https://veekaybee.github.io/2022/09/10/on-the-team-as-a-system/</link><pubDate>Sat, 10 Sep 2022 00:00:00 +0000</pubDate><guid>https://veekaybee.github.io/2022/09/10/on-the-team-as-a-system/</guid><description>Crowded Boat II, Robert Goodnough
I read this great post over the weekend and this sentence is the heart of understanding how to operate a great software team:
Software quality is more the result of a system designed to produce quality, and not so much the result of individual performance. The whole post is good and you should read it, but for me it immediately brought to mind a podcast from 2019 called “The Dysfunction of Organizations” on the same topic.</description></item><item><title>How to prepare an AWS test image for PyTorch</title><link>https://veekaybee.github.io/2022/07/26/how-to-prepare-an-aws-test-image-for-pytorch/</link><pubDate>Tue, 26 Jul 2022 00:00:00 +0000</pubDate><guid>https://veekaybee.github.io/2022/07/26/how-to-prepare-an-aws-test-image-for-pytorch/</guid><description>I&amp;rsquo;ve been getting started in open-source development with PyTorch, starting with running and testing the examples for Pytorch in distributed mode. Big thanks to Mark for reviewing and merging my first PR.
My current Macbook Pro doesn&amp;rsquo;t support using PyTorch with GPUs, although as of 1.12 that&amp;rsquo;s changed and you can read Sebastian&amp;rsquo;s review of his experience with it here. But for me, the easiest way to run PyTorch and its associated tests is to spin up a relatively small GPU-based instance in AWS for testing (GCP offers similar functionality) and then tear it down.</description></item><item><title>Looking back at two years at Automattic and Tumblr</title><link>https://veekaybee.github.io/2022/07/25/looking-back-at-two-years-at-automattic-and-tumblr/</link><pubDate>Mon, 25 Jul 2022 00:00:00 +0000</pubDate><guid>https://veekaybee.github.io/2022/07/25/looking-back-at-two-years-at-automattic-and-tumblr/</guid><description>SeaCoast Farewell, Ivan Aivazovsky
For the past two years, I&amp;rsquo;ve been building and breaking recommender systems at Wordpress.com and Tumblr. I&amp;rsquo;m starting a new adventure soon, but this scope of work has been the most meaningful and fun of my career so far, and I wanted to reflect on a few things I&amp;rsquo;m taking away.
The usual disclaimer in the age of context collapse and hyperbole apply: all of these takes are extremely personal and don&amp;rsquo;t necessarily generalize beyond you = (me - 2 years).</description></item><item><title>On owning a software problem</title><link>https://veekaybee.github.io/2022/02/21/on-owning-a-software-problem/</link><pubDate>Mon, 21 Feb 2022 00:00:00 +0000</pubDate><guid>https://veekaybee.github.io/2022/02/21/on-owning-a-software-problem/</guid><description>This weekend, I saw a tweet that really resonated with me, and judging by the comments, resonated with a lot of others, too.
It reads,
&amp;ldquo;My buddy is an electrician and told me a few months ago that he always leaves the screws in a vertical position on jobs as a sign of craftsmanship. Been thinking ever since what my “vertical screws” equivalent is for product design.&amp;rdquo;
This is so great.</description></item><item><title>Git, SQL, CLI</title><link>https://veekaybee.github.io/2022/01/09/git-sql-cli/</link><pubDate>Sun, 09 Jan 2022 00:00:00 +0000</pubDate><guid>https://veekaybee.github.io/2022/01/09/git-sql-cli/</guid><description>I have this working theory that there are some fundamental tools that you&amp;#39;ll need in any technical job, across time and job descriptions and stacks, and that those three tools are version control (more specifically git), SQL, and bash.
&amp;mdash; Vectorella (@vboykis) October 23, 2021 I&amp;rsquo;ve now written data-centric code across 6 different companies (12 if you count the different companies I consulted for when I was in consulting). I&amp;rsquo;ve so far worked in Python, Scala, Java, SAS, Eviews, R, and, for brief time in undergrad econometrics,Stata.</description></item><item><title>Migrating to Hugo</title><link>https://veekaybee.github.io/2022/01/08/migrating-to-hugo/</link><pubDate>Sat, 08 Jan 2022 00:00:00 +0000</pubDate><guid>https://veekaybee.github.io/2022/01/08/migrating-to-hugo/</guid><description>Over the holiday break, I decided to suck it up and migrate my blog to Hugo.
This week is that week. https://t.co/0KNejJM1kq
&amp;mdash; Vectorella (@vboykis) December 27, 2021 My current stack is now:
Hugo static site generator Hosted on GitPages with GitHub Action rebuilds and domain forwarding by AWS Route53 since I already have a bunch of stuff in AWS and it was easy to manage domain purchases from there. Blog migrations are always a pain, but in theory static site generators should be much easier because all you&amp;rsquo;re doing is migrating Markdown.</description></item><item><title>2021 Work Recap, or the conjoined triangles of success</title><link>https://veekaybee.github.io/2022/01/02/2021-work-recap-or-the-conjoined-triangles-of-success/</link><pubDate>Sun, 02 Jan 2022 00:00:00 +0000</pubDate><guid>https://veekaybee.github.io/2022/01/02/2021-work-recap-or-the-conjoined-triangles-of-success/</guid><description>Last year was an amazing year at work for me, easily one of the highlights of my career so far. I got to work more closely with Scala in both Scalding and Spark, learned PHP so I could deploy an website to millions of users, did a deep dive on recommender systems, broke and fixed Airflow, learned Flink, and generally worked really, really, hard. Quite honestly, 2021 is the hardest I&amp;rsquo;ve ever worked in my professional life, and I don&amp;rsquo;t particularly consider myself someone who shies away from grinding through stuff.</description></item><item><title>The programmer's brain in the lands of exploration and production</title><link>https://veekaybee.github.io/2021/11/07/the-programmers-brain-in-the-lands-of-exploration-and-production/</link><pubDate>Sun, 07 Nov 2021 00:00:00 +0000</pubDate><guid>https://veekaybee.github.io/2021/11/07/the-programmers-brain-in-the-lands-of-exploration-and-production/</guid><description>A lot of my brain space lately has been occupied by TypedPipes. A TypedPipe is the main object type that you work with in Scalding, a distributed data framework written as a wrapper in Scala around Cascading. Scalding was originally developed at Twitter, and adopted by many companies around the same time Apache Spark became popular.
A TypedPipe is a distributed array that “may or may not have been materialized to disk”, aka it’s a very large list of elements that exists mainly in the memory space of your program, where the memory space is usually the nodes of a distributed computational cluster.</description></item><item><title>Recsys 2021 Recap</title><link>https://veekaybee.github.io/2021/10/28/recsys-2021-recap/</link><pubDate>Thu, 28 Oct 2021 00:00:00 +0000</pubDate><guid>https://veekaybee.github.io/2021/10/28/recsys-2021-recap/</guid><description>April, Allan D&amp;rsquo;Arcangelo
Recsys 2021 was in October. Since I&amp;rsquo;m now focusing on this area of ML at work, I attended (virtually only, unfortunately, but the online experience was as good as it could be at a hybrid conference, so major hats off to the organizers!) at took around 30 pages of notes.
There was SO much content! In the interest of condensing my learnings before I forget them, here is some of the high-level content that was most interesting to me.</description></item><item><title>Doing small, fun projects</title><link>https://veekaybee.github.io/2021/10/10/doing-small-fun-projects/</link><pubDate>Sun, 10 Oct 2021 00:00:00 +0000</pubDate><guid>https://veekaybee.github.io/2021/10/10/doing-small-fun-projects/</guid><description>Airplane on Train, Natalia Goncharova
Last year, I gave a keynote at RStudio Conf where I encouraged people to fight the ennui of pandemic life and the boxed-in social platforms we operate on by building up their digital gardens.
I gave a few smaller examples of ways to do that, and now I have another one: building fun Streamlit apps.
Last year, I built a Streamlit app that did natural language processing to generate thinkpieces.</description></item><item><title>Reaching MLE (machine learning enlightenment)</title><link>https://veekaybee.github.io/2021/09/23/reaching-mle-machine-learning-enlightenment/</link><pubDate>Thu, 23 Sep 2021 00:00:00 +0000</pubDate><guid>https://veekaybee.github.io/2021/09/23/reaching-mle-machine-learning-enlightenment/</guid><description>Ivan Shishkin, The Field of Wheat
Once, on a crisp cloudless morning in early fall, a machine learning engineer left her home to seek the answers that she could not find, even in the newly-optimized Google results.
She closed her laptop, put on her backpack and hiking boots, and walked quietly out her door and past her mailbox, down a dusty path that led past a stream, until the houses around her gave way to broad fields full of ripening corn.</description></item><item><title>The local minima of suckiness</title><link>https://veekaybee.github.io/2021/08/05/the-local-minima-of-suckiness/</link><pubDate>Thu, 05 Aug 2021 00:00:00 +0000</pubDate><guid>https://veekaybee.github.io/2021/08/05/the-local-minima-of-suckiness/</guid><description>Key and Hand, Tamara Lempicka, 1941
I don&amp;rsquo;t usually deal in absolutes, but I now know this one thing to be fundamentally true: no one becomes a good software engineer by themselves. But in an industry that has always prided itself on the myth of the superstar ninja, the lone wolf, the self-taught genius, it can seem like good developers are not born - they rise out of the ground, fully-formed and churning out PRs in their wake.</description></item><item><title>Writing for distributed teams</title><link>https://veekaybee.github.io/2021/07/17/writing-for-distributed-teams/</link><pubDate>Sat, 17 Jul 2021 00:00:00 +0000</pubDate><guid>https://veekaybee.github.io/2021/07/17/writing-for-distributed-teams/</guid><description>This week was my first anniversary since I started at Automattic in the spring of 2020, and I was going through my work artifacts to reflect on what I&amp;rsquo;ve done so far this year. One thing that completely surprised me was that it turns out that I only sent 11 emails this entire year.
How is it possible? The answer is P2s.
For those not familiar with Automattic, the company behind WordPress.</description></item><item><title>The ritual of the deploy</title><link>https://veekaybee.github.io/2021/06/20/the-ritual-of-the-deploy/</link><pubDate>Sun, 20 Jun 2021 00:00:00 +0000</pubDate><guid>https://veekaybee.github.io/2021/06/20/the-ritual-of-the-deploy/</guid><description>The Ship The Twelve Apostles, Ivan Aiazovsky
Humans have always been terrible at dealing with uncertainty. Historically, we used to cope with it by inventing superstitions. The ancient world is filled with rituals to ward off potential ill omens during times that were especially out of the control of human capability.
A big example of this has been seafaring. Since six months to a year in a ship headed to an unknown destination with unknown weather events was a high-anxiety event, humans developed a host of superstitions to deal with them.</description></item><item><title>The humble hash aggregate</title><link>https://veekaybee.github.io/2021/06/06/the-humble-hash-aggregate/</link><pubDate>Sun, 06 Jun 2021 00:00:00 +0000</pubDate><guid>https://veekaybee.github.io/2021/06/06/the-humble-hash-aggregate/</guid><description>This post is an expansion of this tweet:
If I had to pick a single programming concept where understanding it is like a superpower, it would probably be the hash map (aka in Python, the humble dictionary) because I&amp;#39;ve seen the pattern come up in almost every kind of data/programming work I&amp;#39;ve ever done.
&amp;mdash; Vectorella (@vboykis) July 8, 2020 One of the important ways we learn when we&amp;rsquo;re growing up is by understanding patterns.</description></item><item><title>The ghosts in the data</title><link>https://veekaybee.github.io/2021/03/26/the-ghosts-in-the-data/</link><pubDate>Fri, 26 Mar 2021 00:00:00 +0000</pubDate><guid>https://veekaybee.github.io/2021/03/26/the-ghosts-in-the-data/</guid><description>Bernadette Resha, Gathering of Ghosts (2014)
Something I&amp;rsquo;ve been thinking about recently as I&amp;rsquo;ve been working at a company that operates entirely remotely and mostly asynchronously during a time when most companies are working in some variation of this model is the idea of implicit versus explicit knowledge.
Explicit knowledge is anything that you can read about, knowledge that&amp;rsquo;s easy to share and pass on. Implicit knowledge is knowledge that people gain by context that&amp;rsquo;s very hard to pull out consciously.</description></item><item><title>Getting machine learning to production</title><link>https://veekaybee.github.io/2020/06/09/getting-machine-learning-to-production/</link><pubDate>Tue, 09 Jun 2020 00:00:00 +0000</pubDate><guid>https://veekaybee.github.io/2020/06/09/getting-machine-learning-to-production/</guid><description>Art: The Other Side of the Rainbow, Roland Petersen, 1972
Table of Contents
Intro The Mystery of Deploying ML Trying to Create Gandinsky Trying to Create Venti Venti Architecture Generating Venti Inferences Putting Venti on Streamlit Splitting out inference and front-end Deploying to the Cloud Lessons Learned Deploying is hard Deep learning is deceptively easy Go for prebuilt as much as possible Understand networking and scale Iterate quickly I haven&amp;rsquo;t seen many posts in the wild on how end-to-end machine learning works, so this post covers the process of creating an end-to-end proof-of-concept (POC) machine learning product, Venti, which is a Medium-like site that generates VC thinkpieces.</description></item></channel></rss>