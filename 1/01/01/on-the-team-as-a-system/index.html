<!doctype html><html lang=en-us><head><meta http-equiv=x-clacks-overhead content="GNU Terry Pratchett"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" href=https://veekaybee.github.io/static/images/logo.png><title>On the team as a system | ★❤✰ Vicki Boykis ★❤✰</title><meta name=title content="On the team as a system"><meta name=description content="How humans work together to build software"><meta name=keywords content><meta property="og:title" content="On the team as a system"><meta property="og:description" content="How humans work together to build software"><meta property="og:type" content="article"><meta property="og:url" content="https://veekaybee.github.io/1/01/01/on-the-team-as-a-system/"><meta property="og:image" content="https://veekaybee.github.io/images/logo.png"><meta property="article:section" content="blog"><meta property="og:site_name" content="★ Vicki Boykis ★ "><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://veekaybee.github.io/images/logo.png"><meta name=twitter:title content="On the team as a system"><meta name=twitter:description content="How humans work together to build software"><meta name=twitter:site content="@vboykis"><meta itemprop=name content="On the team as a system"><meta itemprop=description content="How humans work together to build software"><meta itemprop=wordCount content="738"><meta itemprop=image content="https://veekaybee.github.io/images/logo.png"><meta itemprop=keywords content><meta name=referrer content="no-referrer-when-downgrade"><style>body{font-family:Verdana,sans-serif;margin:auto;padding:20px;max-width:720px;text-align:left;background-color:#fff;word-wrap:break-word;overflow-wrap:break-word;line-height:1.5;color:#444}h1,h2,h3,h4,h5,h6,strong,b{color:#222}a{color:#3273dc}.title{text-decoration:none;border:0}.title span{font-weight:400}nav a{margin-right:10px}textarea{width:100%;font-size:16px}input{font-size:16px}content{line-height:1.6}table{width:100%}img{max-width:100%}code{padding:2px 5px;background-color:#f2f2f2}pre code{color:#222;display:block;padding:20px;white-space:pre-wrap;font-size:14px}div.highlight pre{background-color:initial;color:initial}div.highlight code{background-color:unset;color:unset}blockquote{border-left:1px solid #999;color:#222;padding-left:20px;font-style:italic}footer{padding:25px;text-align:center}.helptext{color:#777;font-size:small}.errorlist{color:#eba613;font-size:small}ul.blog-posts{list-style-type:none;padding:unset}ul.blog-posts li{display:flex}ul.blog-posts li span{flex:0 0 130px}ul.blog-posts li a:visited{color:#8b6fcb}@media(prefers-color-scheme:dark){body{background-color:#333;color:#ddd}h1,h2,h3,h4,h5,h6,strong,b{color:#eee}a{color:#8cc2dd}code{background-color:#777}pre code{color:#ddd}blockquote{color:#ccc}textarea,input{background-color:#252525;color:#ddd}.helptext{color:#aaa}}</style><style type=text/css>h2{size:5px}</style></head><body><header><a href=/ class=title><h2>★❤✰ Vicki Boykis ★❤✰</h2></a><nav><a href=/>Tech Blog</a>
<a href=/essays>Essays</a>
<a href=/index.xml>Tech RSS</a>
<a href=https://boringml.com>Boring ML</a>
<a href=https://www.twitter.com/vboykis>Twitter</a>
<a href=https://www.github.com/veekaybee>GitHub</a>
<a href=/about>About</a></nav></header><main><h1>On the team as a system</h1><p><i><time datetime=0001-01-01 pubdate>Jan 1 0001</time></i></p><content><p><figure><img src=https://raw.githubusercontent.com/veekaybee/veekaybee.github.io/master/static/images/crowdedboat.png width=600px></figure><strong>Crowded Boat II, Robert Goodnough</strong></p><p>I&rsquo;ve been getting started in open-source development with PyTorch, starting with <a href=https://github.com/pytorch/examples/pull/988>running and testing the examples for Pytorch in distributed mode.</a> Big thanks <a href=https://twitter.com/marksaroufim>to Mark</a> for reviewing and merging my first PR.</p><p>My current Macbook Pro doesn&rsquo;t support using PyTorch with GPUs, although as of <a href=https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/>1.12 that&rsquo;s changed</a> and you can read Sebastian&rsquo;s <a href=https://sebastianraschka.com/blog/2022/pytorch-m1-gpu.html>review of his experience with it here</a>. But for me, the easiest way to run PyTorch and its associated tests is to spin up a relatively small GPU-based instance in AWS for testing (GCP offers similar functionality) and then tear it down.</p><p>I&rsquo;ve updated the instructions <a href=https://github.com/pytorch/examples/blob/main/CONTRIBUTING.md#for-bug-fixes>in the official docs</a>, but thought I&rsquo;d add them here as well, mostly as reference to myself for how to do it.</p><p>These instructions assume you have:</p><ol><li>An AWS account and</li><li><a href=https://aws.amazon.com/cli/>AWS CLI set up</a></li><li>A <a href=https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html>unique key-pair</a> for logging into your instance</li></ol><p>We&rsquo;ll be spinning up a <code>g4dn.4xlarge</code> <a href=https://aws.amazon.com/ec2/instance-types/g4/>instance</a>. This is the lowest-cost GPU instance and is fine for a couple hours of testing example runs. If your model is large and memory-intensive, you&rsquo;ll want something larger.</p><p>Current specs (as of summer 2022) are: <code>1 GPU, 16 vCPUs, 64 GiB of memory, 225 NVMe SSD, up to 25 Gbps network performance</code>. The cost is $1.20/hour, so if you accidentally leave it running for a month, <a href=https://calculator.aws/#/estimate>it&rsquo;s going to cost ~$560.</a> One quick way to pre-empt this is to set up <a href=https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/monitor_estimated_charges_with_cloudwatch.html>billing alarms.</a></p><p>We&rsquo;ll be creating this instance from the AWS CLI, although you can also do this from the console, just takes a bit longer.</p><p>From the command line, run the command to create a new EC2 instance:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>--image-id - the ID of the g4dn.4xlarge AMI
</span></span><span style=display:flex><span>--instance-type - g4dn.4xlarge, our Deep Learning Instance Type
</span></span><span style=display:flex><span>--key-name pytorch - the EC2 key you created
</span></span><span style=display:flex><span>--security-groups <span style=color:#f92672>[</span>your security group<span style=color:#f92672>]</span> - make sure this security group has ingress/egress <span style=color:#66d9ef>for</span> port 80, 22, and <span style=color:#ae81ff>443</span>
</span></span></code></pre></div><p>Note: the ID of the image gets updated every several days, <a href=https://gist.github.com/daveadams/8b67859c577f069b62fbea844c67d68a>here&rsquo;s a script</a> to find out what it is when you create the image. thanks, <a href=https://twitter.com/daveadams/status/1553003799454810113>David</a>!</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>aws ec2 run-instances --image-id ami-0403bb4876c18c180 --instance-type g4dn.4xlarge --key-name pytorch  --security-groups <span style=color:#f92672>[</span>your security group<span style=color:#f92672>]</span>
</span></span></code></pre></div><p>Once it&rsquo;s set up, ssh into it using:</p><p><code>ssh -i "yourkey.pem" ubuntu@theinstancename.compute-1.amazonaws.com</code> (<code>ubuntu</code> is the user here)</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#f92672>=============================================================================</span>
</span></span><span style=display:flex><span>       __|  __|_  <span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>       _|  <span style=color:#f92672>(</span>     /   Deep Learning AMI <span style=color:#f92672>(</span>Ubuntu 18.04<span style=color:#f92672>)</span> Version <span style=color:#ae81ff>59</span>
</span></span><span style=display:flex><span>      ___|<span style=color:#ae81ff>\_</span>__|___|
</span></span><span style=display:flex><span><span style=color:#f92672>=============================================================================</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Welcome to Ubuntu 18.04.6 LTS <span style=color:#f92672>(</span>GNU/Linux 5.4.0-1069-aws x86_64v<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Please use one of the following commands to start the required environment with the framework of your choice:
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> TensorFlow 2.7 with Python3.8 <span style=color:#f92672>(</span>CUDA 11.2 and Intel MKL-DNN<span style=color:#f92672>)</span> ____________________________ source activate tensorflow2_p38
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> PyTorch 1.10 with Python3.8 <span style=color:#f92672>(</span>CUDA 11.1 and Intel MKL<span style=color:#f92672>)</span> ______________________________________ source activate pytorch_p38
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> AWS MX 1.8 <span style=color:#f92672>(</span>+Keras2<span style=color:#f92672>)</span> with Python3.7 <span style=color:#f92672>(</span>CUDA 11.0 and Intel MKL-DNN<span style=color:#f92672>)</span> ____________________________ source activate mxnet_p37
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> AWS MX<span style=color:#f92672>(</span>+AWS Neuron<span style=color:#f92672>)</span> with Python3 __________________________________________________ source activate aws_neuron_mxnet_p36
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> Tensorflow<span style=color:#f92672>(</span>+AWS Neuron<span style=color:#f92672>)</span> with Python3 _________________________________________ source activate aws_neuron_tensorflow_p36
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> PyTorch <span style=color:#f92672>(</span>+AWS Neuron<span style=color:#f92672>)</span> with Python3 ______________________________________________ source activate aws_neuron_pytorch_p36
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> AWS MX<span style=color:#f92672>(</span>+Amazon Elastic Inference<span style=color:#f92672>)</span> with Python3 ______________________________________ source activate amazonei_mxnet_p36
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> base Python3 <span style=color:#f92672>(</span>CUDA 11.0<span style=color:#f92672>)</span> _______________________________________________________________________ source activate python3
</span></span></code></pre></div><p>The deep learning instance comes with PyTorch pre-buildt in a conda environment, but these dependencies tend to fall out of sync with each other. Usually it&rsquo;s easier to start from scratch, especially since <code>examples</code> <a href=https://github.com/pytorch/examples/blob/7ed7ac7b01add7ca29d45f25700e73a4b517ccea/run_python_examples.sh#L41>installs its own dependencies.</a></p><p>So then you can run:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e>#!/bin/bash -x
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>mkdir -p /home/ubuntu/my_examples 
</span></span><span style=display:flex><span>cd /home/ubuntu/my_examples 
</span></span><span style=display:flex><span>chown -R 1000:1000 .
</span></span><span style=display:flex><span>git clone https://github.com/pytorch/examples.git 
</span></span><span style=display:flex><span>cd examples
</span></span><span style=display:flex><span>echo <span style=color:#e6db74>&#34;. /home/ubuntu/anaconda3/etc/profile.d/conda.sh&#34;</span> &gt;&gt; /home/ubuntu/.bashrc
</span></span><span style=display:flex><span>. /home/ubuntu/anaconda3/etc/profile.d/conda.sh
</span></span><span style=display:flex><span>source /home/ubuntu/.bashrc
</span></span><span style=display:flex><span>conda create --name pytorchenv 
</span></span><span style=display:flex><span>conda activate pytorchenv
</span></span><span style=display:flex><span>conda install  -c pytorch torchvision cudatoolkit<span style=color:#f92672>=</span>10.1
</span></span></code></pre></div><p>And you should be good to go!</p><p>There is an even easier way to do this if you want to avoid having to run a bunch of bash commands, you can also package the commands as part of the install command using <code>--user-data</code>, <a href=https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/user-data.html>which pushes data to your image at launch.</a> Here&rsquo;s <a href=https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/user-data.html>more on how user-data works.</a></p><p>In order to push data to the image, you have to use an instance profile, <a href=https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2_instance-profiles.html>which is tied to an IAM role</a>,and which you can set up using the command line. It&rsquo;s important to note that the file, even though it runs bash, is a text file.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>aws ec2 run-instances --image-id ami-0403bb4876c18c180 --instance-type g4dn.4xlarge --key-name pytorch --security-groups <span style=color:#f92672>[</span>your security group<span style=color:#f92672>]</span> --iam-instance-profile <span style=color:#e6db74>&#39;{&#34;Name&#34;: &#34;EC2_Access&#34; }&#39;</span> --user-data file://install_pytorch.txt 
</span></span></code></pre></div><p>In order to make sure that your bash script ran correctly, you can tail the image setup logs, which are located in these two places:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>/var/log/cloud-init.log 
</span></span><span style=display:flex><span>/var/log/cloud-init-output.log
</span></span></code></pre></div></content><p></p></main><footer>Made with <a href=https://github.com/janraasch/hugo-bearblog/>Hugo ʕ•ᴥ•ʔ Bear</a></footer></body></html>